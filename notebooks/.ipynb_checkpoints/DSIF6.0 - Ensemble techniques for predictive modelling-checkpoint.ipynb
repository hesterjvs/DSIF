{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DH1XQ07F5Bx8"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this session, we'll explore some advanced topics in machine learning (ML): ensemble models, model interpretability, and hyperparameter tuning. These concepts will be introduced theoretically and then applied to hands-on examples.\n",
    "\n",
    "Throughout the session, we'll use the Lending Club dataset, focusing on predicting loan defaults.\n",
    "\n",
    "### Agenda:\n",
    "\n",
    "0. **Decision trees**\n",
    "1. **Ensemble models**\n",
    "2. **Model interpretability and explainability frameworks**\n",
    "3. **Hyperparameter tuning**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXbLFq-4Q7db"
   },
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPWHwVBUQ7db"
   },
   "source": [
    "#### User-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1725080924521,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "I9SOk8ZsQ7dc"
   },
   "outputs": [],
   "source": [
    "python_material_folder_name = \"python-material\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnHhMhJoQ7dd"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24337,
     "status": "ok",
     "timestamp": 1725080949186,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "7RMqugvwQ7dd",
    "outputId": "c742dc13-728f-4b7e-bf99-f00bd0cf3fbb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Check if in Google Colab environment\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    # Mount drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Set up path to Python material parent folder\n",
    "    path_python_material = rf\"drive/MyDrive/{python_material_folder_name}\"\n",
    "        # If unsure, print current directory path by executing the following in a new cell:\n",
    "        # !pwd\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    # If working locally on Jupyter Notebook, parent folder is one folder up (assuming you are using the folder structure shared at the beginning of the course)\n",
    "    path_python_material = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnHhMhJoQ7dd"
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 6456,
     "status": "ok",
     "timestamp": 1725080955640,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "QozcQmQ5Q7df",
    "outputId": "6369352c-7a02-4604-aecd-671beda341d0"
   },
   "outputs": [],
   "source": [
    "# Read data that was exported from previous session\n",
    "df = pd.read_csv(f\"{path_python_material}/data/2-intermediate/df_out_dsif5.csv\").sample(20000)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1725080955640,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "htUJrbFbQ7di"
   },
   "outputs": [],
   "source": [
    "# Selected features\n",
    "features = ['fico_range_high', 'fico_range_low', 'annual_inc', 'dti']\n",
    "X = df[features]\n",
    "y = df['loan_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixYcWswPQ7de"
   },
   "source": [
    "# 0. Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Decision Tree** is a supervised learning algorithm used for both classification and regression tasks. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "The decision tree algorithm works by recursively splitting the dataset into smaller subsets based on feature values. The \"tree\" is built by selecting features that best split the data at each node (branch point). These splits are made to maximize the **information gain** or minimize the **Gini impurity** (for classification tasks).\n",
    "\n",
    "-   **Root Node:** The top-most node that contains the entire dataset.\n",
    "-   **Internal Nodes:** Points where data is split based on a feature condition.\n",
    "-   **Leaf Nodes:** The terminal nodes of the tree where a final decision is made (classification or regression).\n",
    "\n",
    "See visual example [here](https://en.wikipedia.org/wiki/Decision_tree_learning#/media/File:Decision_Tree.jpg)\n",
    "\n",
    "\n",
    "## 0.1\\. **Building a Simple Decision Tree (Using the Lending Club Dataset)**\n",
    "\n",
    "Let's build a simple Decision Tree classifier on the Lending Club dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree Classifier \n",
    "decision_tree = DecisionTreeClassifier(max_depth=3, \n",
    "                                       random_state=42\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "y_prob = decision_tree.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Decision Tree: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsif6utility import model_evaluation_report\n",
    "model_evaluation_report(X_test, y_test, y_pred, y_prob[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:BLUE\"> >>> DISCUSSION:\n",
    "> What is the above telling us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have now imported the function from a different file..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. **Understanding how decision trees make predictions**\n",
    "\n",
    "Once a decision tree is built, it uses a series of **if-then** conditions to classify or predict outcomes. Each internal node in the tree represents a decision based on a feature and a threshold value, and each leaf node represents a final prediction.\n",
    "\n",
    "-   **How it Predicts:**\n",
    "    1.  Start at the root node.\n",
    "    2.  Follow the tree down, making decisions at each internal node (based on feature values).\n",
    "    3.  Arrive at a leaf node, which gives the predicted outcome.\n",
    "\n",
    "You can visualize the tree to better understand the decision-making process. Here's how to plot a simple decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(\n",
    "        decision_tree,\n",
    "        feature_names=X.columns,\n",
    "        class_names=['Class 0', 'Class 1'],\n",
    "        filled=True,\n",
    "        rounded=True\n",
    "        )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting the plot:**\n",
    "\n",
    "-   **Internal nodes:** Each node shows which feature is used for splitting, the threshold value, and the Gini impurity (a measure of how mixed the classes are at that point).\n",
    "-   **Leaf nodes:** These represent the predicted class based on the features traversed.\n",
    "-   **Color intensity:** The color intensity of the nodes reflects the degree of purity (the more homogeneous the classes are in a node, the deeper the color).\n",
    "\n",
    "**Colour coding:**\n",
    "The color intensity of each box reflects the **purity** of the node with respect to the target classes.  \n",
    "-   **Pure Node:** If all the samples in a node belong to a single class, the node will have a deep, intense color. A pure node is one where the majority (or all) of the data points belong to one class.  \n",
    "-   **Impure Node:** If the samples are evenly split between classes, the color will be lighter or more faded, indicating mixed classes at that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3\\. **Picking the depth of a tree**\n",
    "**Max Depth:** The depth of a decision tree is a critical hyperparameter that controls how many splits the tree can make from the root to a leaf.\n",
    "-   **Shallow Trees (Low Depth):** Tend to underfit the data, as they are too simple and may not capture important patterns.\n",
    "-   **Deep Trees (High Depth):** Tend to overfit the data, as they may capture noise in the training data, leading to poor generalization.-   \n",
    "    \n",
    "**How to Choose Depth:**\n",
    "-   Use cross-validation to find the optimal depth that balances model performance and overfitting.\n",
    "-   A common approach is to plot the tree depth against the model's accuracy on both training and validation sets. The goal is to find a depth where validation accuracy stabilizes or starts to drop (indicating overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# List to store AUC values\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "\n",
    "# Range of depths to evaluate\n",
    "depth_range = np.arange(1, 10)\n",
    "\n",
    "# Loop over each depth\n",
    "for depth in depth_range:\n",
    "    # Initialize Decision Tree with the current max depth\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    \n",
    "    # Fit the model on training data\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the ROC AUC calculation\n",
    "    y_train_pred_prob = decision_tree.predict_proba(X_train)[:, 1]\n",
    "    y_test_pred_prob = decision_tree.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate ROC AUC for both training and test sets\n",
    "    train_auc.append(roc_auc_score(y_train, y_train_pred_prob))\n",
    "    test_auc.append(roc_auc_score(y_test, y_test_pred_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ROC AUC scores for training and validation sets\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depth_range, train_auc, label='Training AUC', marker='o', color='blue')\n",
    "plt.plot(depth_range, test_auc, label='Test AUC', marker='o', color='red')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('ROC AUC Score')\n",
    "plt.title('Tree Depth vs. ROC AUC Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:BLUE\"> >>> DISCUSSION:\n",
    "> At what depth would you stop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM_tj2jLQ7de"
   },
   "source": [
    "# 1. Ensemble Models in Machine Learning\n",
    "\n",
    "## 1.1 Introduction to Ensemble Models\n",
    "\n",
    "**What are Ensemble Models?**\n",
    "\n",
    "Ensemble models combine multiple individual models (often referred to as \"weak learners\") to produce a more robust and accurate prediction. The idea is similar to taking the average opinion of multiple experts rather than relying on just one.\n",
    "\n",
    "**Why use Ensemble Models?**\n",
    "- **Improved Accuracy:** By combining the strengths of multiple models, ensemble models often outperform individual models.\n",
    "- **Reduced Overfitting:** Since ensemble methods aggregate predictions, they can mitigate the risk of overfitting to the training data.\n",
    "  \n",
    "**Types of Ensemble Models**\n",
    "\n",
    "1. **Bagging**\n",
    "   - **Concept:** Bagging involves training multiple models independently using different subsets of the data and averaging their predictions. It’s particularly effective in reducing variance.\n",
    "   - **Popular model:** Random Forest\n",
    "\n",
    "2. **Boosting**\n",
    "   - **Concept:** Boosting builds models sequentially, where each model tries to correct the errors of the previous one. The final prediction is a weighted sum of all models' predictions, which reduces both bias and variance.\n",
    "   - **Popular model:** Gradient Boosting Trees (GBT), CatBoost\n",
    "\n",
    "## 1.2 Popular ensemble models\n",
    "\n",
    "**Gradient Boosting Trees (GBT):**\n",
    "\n",
    "- **How it works:** GBT builds trees one at a time, where each new tree focuses on correcting the errors made by the previous ones. It's very powerful for tabular data.\n",
    "- **Pros and Cons:**\n",
    "  - **Pros:** High predictive accuracy, handles different data types well.\n",
    "  - **Cons:** Can be slow to train, prone to overfitting if not tuned properly.\n",
    "\n",
    "**CatBoost:**\n",
    "\n",
    "- **How it works:** CatBoost is a form of gradient boosting that is particularly popular due to its predictive performance, and the fact that it handles categorical features without needing preprocessing.\n",
    "- **Pros and Cons:**\n",
    "  - **Pros:** Handles categorical data without preprocessing, robust against overfitting, fast to train.\n",
    "  - **Cons:** Can be complex to tune.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCvFA6ubQ7de"
   },
   "source": [
    "## 1.3 Implementing a simple ensemble model using the same features selected in the prior session\n",
    "Let's start with a **Random Forest classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1725080957263,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "kzn2wVyVYkV0"
   },
   "outputs": [],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# RandomForestClassifier model in scikit-learn cannot handle missing values represented as NaN (Not a Number), hence replacing\n",
    "# Create an imputer (replace missing values with the mean of the column,\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit the imputer\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 20614,
     "status": "ok",
     "timestamp": 1725080977872,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "Yl316ibTQ7di",
    "outputId": "b1ed4f6c-6a40-4ab1-931f-323b5303f5ae"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (again, given imputer used above)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2277,
     "status": "ok",
     "timestamp": 1725080980143,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "Mq1AW8nIZRXq"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "rf_y_prob = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "model_evaluation_report(X_test, y_test, rf_y_pred, rf_y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3-tKxKHQ7dj"
   },
   "source": [
    "### <span style=\"color:BLUE\"> >>> DISCUSSION:\n",
    "> How is this confusion metric different from the one built earlier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7l_TZswQ7dj"
   },
   "source": [
    "## 1.4 Let's step up our game by increasing the number of features used\n",
    "\n",
    "Increasing the number of features used in a machine learning model can have both potential benefits and drawbacks. Understanding the trade-offs is essential for optimizing model performance.\n",
    "\n",
    "### Reasons to increase the number of features:\n",
    "- More features can capture more details and nuances in the data, potentially leading to **better predictive performance**.\n",
    "- In complex datasets, **interactions between features** may be important for prediction. A larger number of features increases the likelihood of capturing these interactions.\n",
    "- A model with more features can **adapt** to a wider range of scenarios, potentially improving its performance across different subsets of data.\n",
    "- More features can help **reduce bias** by providing the model with more information, thus allowing it to better fit the true underlying distribution of the data.\n",
    "        \n",
    "### Risks to be managed when increasing number of features\n",
    "- **Curse of Dimensionality:** As the number of features increases, the data becomes more sparse, which can make it harder for the model to learn effectively Adding too many features can lead to **overfitting**, where the model becomes too tailored to the training data and performs poorly on new, unseen data.\n",
    "- More features increase the **computational complexity**, leading to longer training times and requiring more computational resources.\n",
    "- **Interpretability**, more features make it harder to understand how the model makes predictions.\n",
    "- **Feature Redundancy:** Some features may be highly correlated, leading to redundancy and not adding much value to the model.    \n",
    "    \n",
    "\n",
    "### How to balance benefits and risks in practice?\n",
    "The decision to increase the number of features should be based on a careful analysis of the trade-offs between model complexity, interpretability, computational cost, and predictive performance. In practice, it's often beneficial to start with a smaller, more manageable feature set, and then gradually add features while monitoring the model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put this in practice on the Lending Club case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting dataset has {len(df.columns)} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question we should pose ourself is: do we need all of the features?  \n",
    "And the answer is NO. Let's understand why.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OeWQdMEQ7dj"
   },
   "source": [
    "## 1.5 Feature selection\n",
    "Feature selection is a crucial step in building machine learning models, especially when dealing with a large number of features. It helps in improving the model's performance by removing irrelevant or redundant features, reducing overfitting, and decreasing computation time.\n",
    "\n",
    "### Approaches:\n",
    "-   **Low variance feature removal:** Removes features with little to no variability across samples, as they contribute minimally to model prediction.\n",
    "-   **Univariate feature selection:** Selects features based on statistical tests (e.g., chi-squared, ANOVA) that measure the relationship between each feature and the target variable independently.\n",
    "-   **Recursive Feature Elimination (RFE):** Iteratively removes the least important features by fitting the model multiple times and pruning features with the lowest importance scores.\n",
    "-   **Sequential feature selection:** Adds or removes features sequentially, starting from an empty set or full set, to find the combination that optimizes model performance based on a scoring metric.\n",
    "\n",
    "Further reading: [scikit learn](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "______\n",
    "\n",
    "\n",
    "In this session, we are going to leverage automatic feature selection via Recursive Feature Elimination, as provided by scikit learn, after doing some initial cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1725080980521,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "ZTgL79FVQ7dj",
    "outputId": "7a68cc76-359c-4cd3-d1b5-7d32d2bc2833"
   },
   "outputs": [],
   "source": [
    "# Let's start reducing the number of features..\n",
    "\n",
    "# Then, let's drop non-numeric features, for illustrative purposes only \n",
    "# *********** NOTE **************\n",
    "# In your assignment you should include them and treat them accordingly\n",
    "# (see 'Feature encoding' in session 3)\n",
    "df_numeric = df.select_dtypes(exclude=['object'])\\\n",
    "                .drop(columns=['id', \n",
    "                             'loan_id_extracted'])\n",
    "print(f\"Number of columns: {len(df_numeric.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, let's drop columns with high percentage of missing values\n",
    "# *********** NOTE **************\n",
    "# In a real-life scenario, we would want to understand data and make sure we are not discarding\n",
    "# useful information before doing this!\n",
    "threshold = 0.5 # Customisable\n",
    "null_percentages = df_numeric.isnull().mean()\n",
    "df_dropped = df_numeric.drop(columns=null_percentages[null_percentages > threshold].index)\n",
    "print(f\"Dropped columns: {null_percentages[null_percentages > threshold].index.tolist()}\")\n",
    "print(f\"Number of columns: {len(df_dropped.columns)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** realistically we would like to retain some of the above columns - for example, `mths_since_last_delinq` could be a very important one where missing data might mean 'no delinquencies', so we may consider replacing with a value of 0. Additionally, we may want to add a `mths_since_last_delinq_MISSING_FLAG` that captures cases where that 0 was assigned manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we remove features that would not be available at time of application\n",
    "# e.g.: total_pymnt which is defined as 'Payments received to date for total amount funded'\n",
    "# This is to prevent phenomenom called 'data leakage', covered later in this notebook.\n",
    "df_dropped = df_dropped.drop(columns = [\"out_prncp\",\n",
    "                             \"out_prncp_inv\",\n",
    "                             \"total_pymnt\",\n",
    "                             \"total_pymnt_inv\",\n",
    "                             \"funded_amnt\",\n",
    "                             \"funded_amnt_inv\"]\n",
    "                            )\n",
    "\n",
    "print(f\"Number of columns: {len(df_dropped.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Null replacement strategies for remaining columns\n",
    "### <span style=\"color:RED\"> NOTE:  </span> Some very strong assumptions here, for illustrative purposes only. For your project/assignments, make sure that any replacement strategy is understood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13456,
     "status": "ok",
     "timestamp": 1725080993973,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "lF6JjCsAQ7dj"
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Group 1: Columns to be filled with 0 \n",
    "# Assuming these features represent counts or amounts where a missing value means zero\n",
    "fill_zero_cols = [\n",
    "    'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m',\n",
    "    'open_act_il', 'open_il_12m', 'open_il_24m',\n",
    "    'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
    "    'all_util', 'inq_fi', 'total_cu_tl', 'acc_open_past_24mths',\n",
    "    'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl',\n",
    "    'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats',\n",
    "    'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', \n",
    "    'inq_last_12m', 'pub_rec_bankruptcies'\n",
    "]\n",
    "df_dropped[fill_zero_cols] = df_dropped[fill_zero_cols].fillna(0)\n",
    "\n",
    "#########################################\n",
    "# Group 2: Columns to be filled with median \n",
    "# (Assuming these features are numeric and can have a central tendency)\n",
    "fill_median_cols = [\n",
    "    'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'mo_sin_old_il_acct',\n",
    "    'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
    "    'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq',\n",
    "    'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'tot_hi_cred_lim',\n",
    "    'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'total_rev_hi_lim'\n",
    "]\n",
    "df_dropped[fill_median_cols] = df_dropped[fill_median_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#########################################\n",
    "# Group 3: Fill with 999\n",
    "fill_nine_cols = [\n",
    "     'mths_since_rcnt_il'\n",
    "]\n",
    "# Apply fill with 999\n",
    "df_dropped[fill_nine_cols] = df_dropped[fill_nine_cols].fillna(999)\n",
    "\n",
    "#########################################\n",
    "# Do a quick check on null values\n",
    "df_dropped.columns[df_dropped.isna().sum() > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinite replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_infinity(df):\n",
    "    infinite_list = df.isin([-np.inf, np.inf]).sum()\n",
    "\n",
    "    if infinite_list.sum() == 0:\n",
    "        print(\"No column has infinite values\")\n",
    "    else:\n",
    "        print(\"Columns with infinite values:\")\n",
    "        print(infinite_list[infinite_list>0])\n",
    "\n",
    "check_infinity(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[df_dropped[\"debt_to_income\"].isin([-np.inf, np.inf])][[\"annual_inc\", \"loan_amnt\", \"debt_to_income\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format  # Display floats with 2 decimal places\n",
    "\n",
    "df_dropped[\"debt_to_income\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[\"debt_to_income\"] = df_dropped[\"debt_to_income\"].replace(np.inf, 999)\n",
    "\n",
    "check_infinity(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export df_dropped following NA replacement\n",
    "df_dropped.to_csv(f\"{path_python_material}/data/2-intermediate/df_out_dsif6.csv\"\n",
    "                        , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1725082439490,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "ISOK7L3AQ7dk",
    "outputId": "22e07fb1-64cf-4f37-d888-66c782b1d161"
   },
   "outputs": [],
   "source": [
    "# Then, let's drop the target variable from X\n",
    "X = df_dropped.drop(columns=['loan_default'])\n",
    "y = df_dropped['loan_default']\n",
    "X_columns = X.columns\n",
    "print(f\"Number of columns: {len(X_columns)}\")\n",
    "\n",
    "# RandomForestClassifier model in scikit-learn cannot handle missing values represented as NaN (Not a Number), hence replacing\n",
    "# Create an imputer (replace missing values with the mean of the column,\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# Fit the imputer\n",
    "X = pd.DataFrame(imputer.fit_transform(X)) # fit_transform returns an array, dataframe needed for Step 4\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1725082442547,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "aI530vomQ7dk"
   },
   "outputs": [],
   "source": [
    "# Step 2: Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "executionInfo": {
     "elapsed": 125197,
     "status": "ok",
     "timestamp": 1725082580938,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "DaNBp3D9Q7dk",
    "outputId": "62affb98-91e3-4441-f710-ab238574a4cb"
   },
   "outputs": [],
   "source": [
    "# Step 3: Apply Recursive Feature Elimination (RFE)\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(estimator=rf,\n",
    "          n_features_to_select=20, # number of features to select\n",
    "          step=30,                  # step=1 means remove one feature at a time\n",
    "          verbose = 3)\n",
    "\n",
    "# Fit RFE to the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1725082580939,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "I8ceyqcr2MMY",
    "outputId": "93c8915b-cd24-48b8-e686-59c9b3c80c7a"
   },
   "outputs": [],
   "source": [
    "# Step 4: Select the top features\n",
    "selected_features = X_train.columns[rfe.support_] # rfe.support_ represents the mask of selected features (i.e. boolean indicator) \n",
    "selected_features_names = X_columns[selected_features]\n",
    "print(\"Selected Features by RFE:\")\n",
    "print(f\"Index: {selected_features}\")\n",
    "print(f\"Column names: {selected_features_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 18013,
     "status": "ok",
     "timestamp": 1725082634144,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "vTN6QATpQ7dl",
    "outputId": "742e04c9-d160-4ba7-df1d-2ffae8d53aca"
   },
   "outputs": [],
   "source": [
    "# Step 5: Train the Random Forest classifier on the selected features\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train[selected_features], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1725082634748,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "zzC7ASjHQ7dl"
   },
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model performance on the test set\n",
    "y_pred_selected = rf_selected.predict(X_test[selected_features])\n",
    "y_prob_selected = rf_selected.predict_proba(X_test[selected_features])[:,1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1725082634748,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "lZ2Km4CFQ7dl",
    "outputId": "b375a0e6-2324-4329-ba38-5bb1657639d7"
   },
   "outputs": [],
   "source": [
    "model_evaluation_report(X_test[selected_features], y_test, y_pred_selected, y_prob_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoQt2wEFQ7dl"
   },
   "source": [
    "### <span style=\"color:BLUE\"> >>> DISCUSSION:</span>\n",
    "This performance is good.. maybe even suspiciously too good... what can have happened here??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pair wise correlation:\n",
    "import seaborn as sns\n",
    "target = 'loan_default'\n",
    "flag_plot = False\n",
    "\n",
    "for col in selected_features_names:\n",
    "    # Calculate correlation\n",
    "    correlation = df_dropped[[col, target]].corr().iloc[0, 1]\n",
    "    \n",
    "    print(f\"Correlation between {col} and {target}: {correlation:.2f}\")\n",
    "    # Create scatter plot\n",
    "    if flag_plot:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.scatterplot(x=df_dropped[col], y=df_dropped[target])\n",
    "\n",
    "        # Add title with correlation value\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(target)\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:BLUE\"> >>> DISCUSSION: \n",
    "> What do you think is happening for `Correlation between recoveries and loan_default` and `Correlation between collection_recovery_fee and loan_default`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data leakage** (or **target leakage**)  \n",
    "Occurs when a feature includes information that would not be available at prediction time, often because it is generated after or is causally linked to the outcome (e.g., using recovery amounts to predict defaults).\n",
    "\n",
    "#### Example in our case:\n",
    "For predicting defaults, using **recovery** data would be an example of **data leakage** because recovery occurs after the default event, making it intrinsically correlated with the outcome you're trying to predict (default). In this case, the model is being trained on information that would not be available at the time of making the prediction, leading to overfitting and unrealistic performance.\n",
    "\n",
    "#### How to address it:\n",
    "-   Remove or avoid using features that represent **future information** or data that is directly derived from the target variable.\n",
    "-   Ensure that predictors are limited to features that would be available **before** the target event occurs (in your case, before the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dropped.drop(columns=['loan_default', \"recoveries\", \"collection_recovery_fee\"])\n",
    "y = df_dropped['loan_default']\n",
    "X_columns = X.columns\n",
    "print(f\"Number of columns: {len(X_columns)}\")\n",
    "\n",
    "# RandomForestClassifier model in scikit-learn cannot handle missing values represented as NaN (Not a Number), hence replacing\n",
    "# Create an imputer (replace missing values with the mean of the column,\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# Fit the imputer\n",
    "X = pd.DataFrame(imputer.fit_transform(X)) # fit_transform returns an array, dataframe needed for Step 4\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 2: Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 3: Apply Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(estimator=rf,\n",
    "          n_features_to_select=20, # n_features_to_select = number of features to select\n",
    "          step=30,                  # step=1 means remove one feature at a time\n",
    "          verbose = 3)\n",
    "\n",
    "# Fit RFE to the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Select the top features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "selected_features_names = X_columns[selected_features]\n",
    "print(\"Selected Features by RFE:\")\n",
    "print(f\"Index: {selected_features}\")\n",
    "print(f\"Column names: {selected_features_names}\")\n",
    "\n",
    "# Step 5: Train the Random Forest classifier on the selected features\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Step 6: Evaluate the model performance on the test set\n",
    "y_pred_selected = rf_selected.predict(X_test[selected_features])\n",
    "y_prob_selected = rf_selected.predict_proba(X_test[selected_features])[:,1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_report(X_test, y_test, y_pred_selected, y_prob_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo3WFO9OQ7dm"
   },
   "source": [
    "2\\. Model Interpretability and Explainability Frameworks\n",
    "--------------------------------------------------------\n",
    "\n",
    "### 2.1 The Challenge of Interpretability in Finance\n",
    "\n",
    "Ensemble models, particularly those that involve many weak learners like GBT or Random Forest, are often seen as \"black boxes.\" While they provide high accuracy, their complexity makes it difficult to understand how they arrive at a specific decision. This lack of transparency can be problematic in finance, where understanding the \"why\" behind a model's prediction is as important as the prediction itself.\n",
    "\n",
    "### 2.2 Techniques for Interpreting Models\n",
    "\n",
    "**Feature Importance:**\n",
    "\n",
    "One of the simplest methods to interpret an ensemble model is to look at the feature importance scores. These scores tell us which features the model found most relevant for making predictions.\n",
    "\n",
    "**SHAP (SHapley Additive exPlanations):**\n",
    "\n",
    "SHAP is a game-theory-based method that provides a consistent and unified measure of feature importance. Unlike simple feature importance, SHAP values give insight into how each feature impacts the model's predictions for individual instances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Feature importance\n",
    "\n",
    "Let's see how we can visualize feature importance in our Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1725082634748,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "d1Ua6cKJQ7dm",
    "outputId": "0f4a279a-87cf-45f9-cac9-35723b34ac01"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = rf_selected.feature_importances_\n",
    "print(type(importances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1725082635380,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "wYgsjuCBQ7dm",
    "outputId": "3f2e3424-88be-428f-f56e-a446a8627583"
   },
   "outputs": [],
   "source": [
    "# Sort the array in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# argsort > returns the indices of the importances array in ascending order.\n",
    "# [::-1]  > reverses the array, making the sorting descending.\n",
    "# It uses Python's slice notation, where the syntax is [start:stop:step]\n",
    "\n",
    "col_labels = X_columns[X[selected_features].columns[indices]]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X[selected_features].shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(ticks = range(X[selected_features].shape[1])\n",
    "           , labels = col_labels, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeVyNWLrQ7dm"
   },
   "source": [
    "**Further reading**: See the following articles for examples on how SHAP can be used instead.\n",
    "- [Medium link](https://medium.com/@anshulgoel991/model-exploitability-using-shap-shapley-additive-explanations-and-lime-local-interpretable-cb4f5594fc1a) (interestingly, also on a random forest classifier :)  )\n",
    "- [Datacamp link](https://www.datacamp.com/tutorial/introduction-to-shap-values-machine-learning-interpretability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1725083801610,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "A3mDg-71Q7d3"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# SHAP TreeExplainer for RandomForestClassifier\n",
    "rf_explainer = shap.TreeExplainer(rf_selected)\n",
    "rf_shap_values = rf_explainer.shap_values(X_test[:10])\n",
    "\n",
    "# Check SHAP values' shape to confirm\n",
    "print(f'RF SHAP values shape: {rf_shap_values[1].shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JS visualization for interactive plots\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_index = 1\n",
    "# Step 1 - calculate expected value of positive class\n",
    "# This is baseline or average prediction of the model for the positive class before any specific features for an observation are considered\n",
    "expected_value_positive_class = rf_explainer.expected_value[1]\n",
    "print(\"expected_value_positive_class:\", expected_value_positive_class)\n",
    "\n",
    "len(rf_shap_values[observation_index][:, 1]),len(X_test.iloc[observation_index])\n",
    "\n",
    "shap.force_plot(expected_value_positive_class\n",
    "                ,  rf_shap_values[0][observation_index] # shap_values_positive_class\n",
    "                , X_test.iloc[observation_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, but **let's make it interactive!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create a function to update SHAP visualizations based on selected observation\n",
    "def update_shap_plot(observation_index):\n",
    "    # Clear the previous output to avoid stacking multiple force plots\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Re-display the slider (since clearing the output also clears the slider)\n",
    "    display(observation_slider)\n",
    "    \n",
    "    feature_names = col_labels\n",
    "    \n",
    "    # Display SHAP force plot for the selected observation\n",
    "    display(shap.force_plot(\n",
    "            expected_value_positive_class\n",
    "                , rf_shap_values[0][observation_index]\n",
    "                , X_test.iloc[observation_index]\n",
    "                , feature_names = feature_names\n",
    "           ))\n",
    "\n",
    "# Create a slider to select the observation (0 to len(X_test)-1)\n",
    "observation_slider = widgets.IntSlider(\n",
    "    value=0, min=0, max=len(X_test[:10])-1, step=1, description='Observation:', continuous_update=True)\n",
    "\n",
    "# Use the interactive function to update the SHAP plot when the slider value changes\n",
    "observation_slider.observe(lambda change: update_shap_plot(change['new']), names='value')\n",
    "\n",
    "# Display the slider and force plot\n",
    "display(observation_slider)\n",
    "\n",
    "# Call update_shap_plot to display the initial SHAP plot\n",
    "update_shap_plot(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rm5qjkBoQ7dm"
   },
   "source": [
    "3\\. Intro to Hyperparameter Tuning\n",
    "----------------------------------\n",
    "\n",
    "### 3.1 Why Hyperparameter Tuning?\n",
    "\n",
    "Hyperparameters are settings that control the learning process of a model.  Unlike the model parameters (like weights), hyperparameters are not learned from the data; they need to be set manually or through a tuning process.\n",
    "\n",
    "\n",
    "**Importance in ML:**\n",
    "-   **Performance:** Properly tuned hyperparameters can dramatically improve model performance\n",
    "-   **Overfitting:** Tuning can help in finding a balance between underfitting and overfitting\n",
    "\n",
    "### 3.2 Methods for Hyperparameter Tuning\n",
    "\n",
    "1.  **Grid Search:**\n",
    "    -   **Concept:** Exhaustively search over a predefined set or range of hyperparameters\n",
    "    -   **Pros:** Guarantueed best combination within the grid\n",
    "    -   **Cons:** Computationally expensive\n",
    "    \n",
    "2.  **Random Search:**\n",
    "    -   **Concept:** Randomly samples combinations of hyperparameters from the predefined range\n",
    "    -   **Pros:** Often finds a good combination with less computational cost\n",
    "    -   **Cons:** No guarantee of finding the absolute best combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrrimJZUQ7do"
   },
   "source": [
    "### <span style=\"color:BLUE\"> **>>> DISCUSSION: Which parameters did we set earlier for our random forest models?**  </span>    \n",
    "\n",
    "**Further resources**: More hyperparameters by common model type [here](https://www.researchgate.net/figure/A-comprehensive-overview-of-common-ML-models-their-hyper-parameters-suit-able_tbl2_343390531)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1148936,
     "status": "ok",
     "timestamp": 1725083784312,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "oWtpgnzXQ7do",
    "outputId": "2ef33876-d3c8-40fc-9402-11bd0b87280a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 200],    # [50, 100, 200],\n",
    "    'max_depth': [3, 10],      # [None, 10, 20, 30],\n",
    "    'min_samples_split': [2]  # [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf_selected,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=2,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Grid Search\n",
    "grid_search.fit(X_train[selected_features], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17292,
     "status": "ok",
     "timestamp": 1725083801306,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "JwaddmjuQ7dp",
    "outputId": "381d795f-b195-421f-81e4-acd1416149a5"
   },
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Fit the model on the training data\n",
    "best_rf.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Step 3: Predict on the test set\n",
    "y_pred = best_rf.predict(X_test[selected_features])\n",
    "y_prob = best_rf.predict_proba(X_test[selected_features])[:,1]\n",
    "\n",
    "model_evaluation_report(X_test[selected_features], y_test, y_pred, y_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Zb4heNMQ7dp"
   },
   "source": [
    "### <span style=\"color:BLUE\"> >>> DISCUSSION:\n",
    "> What do you think could be some of the challenges of this approach?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:BLUE\"> **>>> EXERCISE 1 (optional) - SHAP value interpretation:**  </span>    \n",
    "> Find an observation in your dataset for which the prediction is \"1\" (default). **What factors contributed to that** and is this aligned to expectations? **How would you explain it to a business stakeholder?**  \n",
    "\n",
    "> Now repeat for an observation in your dataset for which the prediction is \"0\" (non default).\n",
    "\n",
    "Feel free to bring your results for discussion in a future office hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1725083801328,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "Od3Pp0NtQ7ds"
   },
   "source": [
    "### <span style=\"color:BLUE\"> **>>> EXERCISE 2 (optional):**  </span> \n",
    "\n",
    "> Review and enhance the strategies adopted for **Feature selection** and **Null replacement** in the beginning of the notebook.  \n",
    "\n",
    "> You will be able to leverage this work in the final assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2v2CielmQ7d3"
   },
   "source": [
    "# End of session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1725083801610,
     "user": {
      "displayName": "Andrea Baroni",
      "userId": "13443912204230378793"
     },
     "user_tz": -60
    },
    "id": "MydnWpy0Q7d3",
    "outputId": "7df7b7bb-eda8-4d5c-b10d-f0f357aa8d6c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=f\"{path_python_material}/images/the-end.jpg\", width=500,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cat Boost implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Initialize the CatBoostClassifier with an overfitting detector\n",
    "cb = CatBoostClassifier(\n",
    "    iterations=500,      # Maximum number of boosting iterations\n",
    "    learning_rate=0.05,  # Learning rate\n",
    "    eval_metric='AUC',   # Metric to monitor\n",
    "    early_stopping_rounds=20,  # Stop if no improvement after X iterations\n",
    "    od_type='Iter',            # Overfitting detection type (detect after fixed number of non-improving iterations)\n",
    "    random_seed=42,\n",
    "    verbose=100                # Print log every X iterations\n",
    ")\n",
    "\n",
    "# Train the model with training and validation data\n",
    "cb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),  # Validation set for monitoring overfitting\n",
    "    use_best_model=True,        # Use the best model from the iterations\n",
    "    plot=True                   # Plot the learning curve\n",
    ")\n",
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "cb_y_pred = cb.predict(X_test)\n",
    "cb_y_prob = cb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "model_evaluation_report(X_test, y_test, cb_y_pred, cb_y_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
