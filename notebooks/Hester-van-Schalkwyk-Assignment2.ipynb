{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea368651-ac05-4601-86b4-6f87f9c39a6a",
   "metadata": {},
   "source": [
    "# <span style=\"color:TEAL\">**ASSIGNMENT #2**</span>\n",
    "Hester van Schalkwyk\n",
    "## Loan Default Prediction Assignment\n",
    " \n",
    "This notebook follows a structured approach to predicting loan defaults using machine learning.\n",
    "The assignment consists of building baseline and improved models, optimizing them based on business constraints, and implementing a regression model for loan amount prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b485fd-09ad-437b-b19e-4f85cf85274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Suppress Future Warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682fcec-f2e2-4197-83e7-943bdba340e8",
   "metadata": {},
   "source": [
    "### **Step 1: Load and Explore Data**\n",
    "\n",
    "Objective:\n",
    "- Load the Lending Club dataset (using a 200-row sample for efficiency). I loaded 200 as the models didn't converge with 100 rows.\n",
    "- Identify categorical and numerical features.\n",
    "- Ensure we have the target variable (loan_status) for classification.\n",
    "\n",
    "Assignment Relevance:\n",
    "- This step ensures a clean dataset for building the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a3c258-78b6-4e3e-8886-9bd5c34351bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>...</th>\n",
       "      <th>int_rate_clean</th>\n",
       "      <th>term_numeric</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>loan_amnt_log</th>\n",
       "      <th>grade_encoded</th>\n",
       "      <th>loan_amnt_std</th>\n",
       "      <th>annual_inc_std</th>\n",
       "      <th>loan_amnt_norm</th>\n",
       "      <th>annual_inc_norm</th>\n",
       "      <th>loan_default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167338079</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.08%</td>\n",
       "      <td>134.93</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>cashier</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>8.294300</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.196895</td>\n",
       "      <td>-0.367206</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71016917</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>9.16%</td>\n",
       "      <td>500.07</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>ABM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>10.085851</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915452</td>\n",
       "      <td>-0.264024</td>\n",
       "      <td>0.592875</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39589826</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.49%</td>\n",
       "      <td>162.49</td>\n",
       "      <td>B</td>\n",
       "      <td>B3</td>\n",
       "      <td>driver</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>8.517393</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.091278</td>\n",
       "      <td>-0.286953</td>\n",
       "      <td>0.109415</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134798709</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>11.05%</td>\n",
       "      <td>522.42</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>10.085851</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915452</td>\n",
       "      <td>-0.418798</td>\n",
       "      <td>0.592875</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127097355</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>13.59%</td>\n",
       "      <td>322.79</td>\n",
       "      <td>C</td>\n",
       "      <td>C2</td>\n",
       "      <td>Shipping Clerk</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>9.546884</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.140722</td>\n",
       "      <td>-0.367206</td>\n",
       "      <td>0.338422</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  loan_amnt  funded_amnt  funded_amnt_inv        term int_rate  \\\n",
       "0  167338079     4000.0       4000.0           4000.0   36 months   13.08%   \n",
       "1   71016917    24000.0      24000.0          24000.0   60 months    9.16%   \n",
       "2   39589826     5000.0       5000.0           5000.0   36 months   10.49%   \n",
       "3  134798709    24000.0      24000.0          24000.0   60 months   11.05%   \n",
       "4  127097355    14000.0      14000.0          14000.0   60 months   13.59%   \n",
       "\n",
       "   installment grade sub_grade       emp_title  ... int_rate_clean  \\\n",
       "0       134.93     B        B5         cashier  ...         0.1308   \n",
       "1       500.07     B        B2             ABM  ...         0.0916   \n",
       "2       162.49     B        B3          driver  ...         0.1049   \n",
       "3       522.42     B        B4             NaN  ...         0.1105   \n",
       "4       322.79     C        C2  Shipping Clerk  ...         0.1359   \n",
       "\n",
       "  term_numeric  debt_to_income loan_amnt_log grade_encoded loan_amnt_std  \\\n",
       "0         36.0        0.083333      8.294300             1     -1.196895   \n",
       "1         60.0        0.421053     10.085851             1      0.915452   \n",
       "2         36.0        0.090909      8.517393             1     -1.091278   \n",
       "3         60.0        0.551724     10.085851             1      0.915452   \n",
       "4         60.0        0.291667      9.546884             2     -0.140722   \n",
       "\n",
       "  annual_inc_std loan_amnt_norm annual_inc_norm loan_default  \n",
       "0      -0.367206       0.083969        0.004364        False  \n",
       "1      -0.264024       0.592875        0.005182        False  \n",
       "2      -0.286953       0.109415        0.005000        False  \n",
       "3      -0.418798       0.592875        0.003955        False  \n",
       "4      -0.367206       0.338422        0.004364        False  \n",
       "\n",
       "[5 rows x 159 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Data (first 200 rows instead of 100 for the model to converge.)\n",
    "df = pd.read_csv(\"../data/2-intermediate/df_out_dsif5.csv\", nrows=200)\n",
    "\n",
    "# Display initial dataset info\n",
    "display(df.head())\n",
    "\n",
    "# Identify target variable and features\n",
    "target = 'loan_status'  # Assuming loan_status is the target variable\n",
    "num_features = df.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target from feature lists\n",
    "num_features = [col for col in num_features if col != target]\n",
    "cat_features = [col for col in cat_features if col != target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d2a6b-ffc7-4229-b9d0-0abcd99fce50",
   "metadata": {},
   "source": [
    "### **Step 2: Preprocess Data (Feature Engineering and Encoding)**\n",
    "\n",
    "Objective:\n",
    "- Handle categorical features by limiting categories to the top 10 most frequent and encoding them via one-hot encoding.\n",
    "- Standardize numerical features to ensure they are on the same scale.\n",
    "\n",
    "Assignment Relevance:\n",
    "- This step implements feature engineering, which is required for building the improved model (`model_2`).\n",
    "- Handling categorical variables properly improves model interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f59f2c-2a76-416d-a741-286e7235685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables (limit to top 10 most frequent values)\n",
    "for col in cat_features:\n",
    "    top_10 = df[col].value_counts().index[:10]\n",
    "    df[col] = df[col].apply(lambda x: x if x in top_10 else 'OTHER')\n",
    "df_encoded = pd.get_dummies(df, columns=cat_features, drop_first=True)\n",
    "\n",
    "# Convert `loan_status` into binary target `loan_default`\n",
    "df_encoded['loan_default'] = df_encoded['loan_status'].apply(lambda x: 1 if x == \"Charged Off\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ede23-eaef-4d29-9ace-22c69414018e",
   "metadata": {},
   "source": [
    "**Feature Engineering (New Features for Model Improvement)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3d7b5f-5f57-456c-bfd0-3797cf936b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['income_to_debt_ratio'] = df_encoded['annual_inc'] / (df_encoded['dti'] + 1)\n",
    "df_encoded['loan_to_income_ratio'] = df_encoded['loan_amnt'] / (df_encoded['annual_inc'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1724fd-b15f-479b-9070-4b1e2ca7ace1",
   "metadata": {},
   "source": [
    "**Preprocessing Pipelines (Handling Missing Values and Scaling)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc572ede-59bd-4d26-9302-c613e4d0dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c570c-3781-4fc5-b331-7c4b3e7cd90c",
   "metadata": {},
   "source": [
    "### **Step 3: Split Data and Handle Missing Values**\n",
    "Objective:\n",
    "- Prepare X (features) and y (target variable).\n",
    "- Ensure no class has fewer than two instances, as this would cause issues in stratified splitting.\n",
    "- Apply SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset and deal with class imbalance.\n",
    "- Handle missing values by replacing them with the median value.\n",
    "\n",
    "Assignment Relevance:\n",
    "- This step ensures our dataset is balanced before training the models.\n",
    "- The handling of class imbalance is explicitly required in the assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc1123f-d209-42aa-a217-d6178f01693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "X = df_encoded.drop(columns=[target, 'loan_status'])\n",
    "y = df_encoded['loan_default']\n",
    "\n",
    "# Ensure no class has less than 2 instances\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "rare_classes = [cls for cls, count in class_counts.items() if count < 2]\n",
    "if rare_classes:\n",
    "    X = X[~np.isin(y, rare_classes)]\n",
    "    y = y[~np.isin(y, rare_classes)]\n",
    "\n",
    "# Perform train-test split without stratification if necessary\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "except ValueError:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values before training\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# **Handle Class Imbalance with SMOTE**\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd9d16-00d8-4cc9-a512-240ec8a23c6e",
   "metadata": {},
   "source": [
    "### **Step 4: Train and Evaluate Baseline Model with Cross-Validation**\n",
    "Objective:\n",
    "- Train a Logistic Regression model as a baseline.\n",
    "- Apply cross-validation to ensure robustness.\n",
    "- Use ROC-AUC as the primary evaluation metric.\n",
    "\n",
    "Assignment Relevance:\n",
    "- Cross-validation is explicitly required.\n",
    "- This forms our baseline model for comparison with `model_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45bcae9-2744-4c07-b41b-572ba878cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Cross-Validation ROC-AUC Scores: [1.         1.         0.99507389 0.97167488 0.99876847]\n",
      "Mean ROC-AUC Score: 0.993103448275862\n",
      "Baseline Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "ROC-AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "baseline_model = LogisticRegression(max_iter=2000, solver='liblinear', penalty='l2', class_weight='balanced')\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(baseline_model, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "print(f\"Baseline Model Cross-Validation ROC-AUC Scores: {cross_val_scores}\")\n",
    "print(f\"Mean ROC-AUC Score: {np.mean(cross_val_scores)}\")\n",
    "\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_pred_baseline_proba = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate Baseline Model\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(classification_report(y_test, y_pred_baseline, zero_division=1))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_baseline_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98326dc2-af13-4db9-a079-8c6e025b7742",
   "metadata": {},
   "source": [
    "### **Step 5: Train and Evaluate Improved Model with Cross-Validation**\n",
    "Objective:\n",
    "- Train a Random Forest Classifier as model_2.\n",
    "- Apply cross-validation for consistency.\n",
    "- Evaluate performance using classification metrics and ROC-AUC.\n",
    "\n",
    "Assignment Relevance:\n",
    "- `model_2` includes feature selection, cross-validation, and a more powerful classifier than the baseline.\n",
    "- This meets the mandatory part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e36755-3c6c-40b5-8354-9e2208479ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_2 Cross-Validation ROC-AUC Scores: [1. 1. 1. 1. 1.]\n",
      "Mean ROC-AUC Score: 1.0\n",
      "Custom Cost-Based Loss: 0\n"
     ]
    }
   ],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
    "cross_val_scores_2 = cross_val_score(model_2, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "print(f\"Model_2 Cross-Validation ROC-AUC Scores: {cross_val_scores_2}\")\n",
    "print(f\"Mean ROC-AUC Score: {np.mean(cross_val_scores_2)}\")\n",
    "\n",
    "model_2.fit(X_train, y_train)\n",
    "y_pred_model_2_proba = model_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# **Custom Cost-Based Loss Function**\n",
    "def custom_loss(y_true, y_pred):\n",
    "    FP_cost = 100\n",
    "    FN_cost = 1000\n",
    "    FP = ((y_true == 0) & (y_pred == 1)).sum()\n",
    "    FN = ((y_true == 1) & (y_pred == 0)).sum()\n",
    "    return FP * FP_cost + FN * FN_cost\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred_model_2_threshold = (y_pred_model_2_proba > threshold).astype(int)\n",
    "print(\"Custom Cost-Based Loss:\", custom_loss(y_test, y_pred_model_2_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301a824-c6e1-42d7-b022-ebfc673768e9",
   "metadata": {},
   "source": [
    "### **Step 6: Train Regression Model for Loan Amount Prediction**\n",
    "Objective:\n",
    "- Consider business cost implications by weighing False Positives (FP) and False Negatives (FN).\n",
    "- Design a custom loss function to minimize financial risk to the lender.\n",
    "\n",
    "Assignment Relevance:\n",
    "- This step is optional but aligns with Part 2 of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1baf0ce1-f771-4492-adcb-f3ca394a29f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Model Performance:\n",
      "Mean Squared Error: 17890972.028226633\n",
      "Root Mean Squared Error (RMSE): 4229.772101216167\n",
      "Mean Loan Amount: 14731.0\n",
      "RMSE as Percentage of Mean Loan Amount: 28.713407787768432 %\n"
     ]
    }
   ],
   "source": [
    "reg_features = [col for col in df_encoded.columns if 'emp_length' in col or 'home_ownership' in col] + ['annual_inc', 'income_to_debt_ratio', 'loan_to_income_ratio']\n",
    "X_reg = df_encoded[reg_features]\n",
    "y_reg = df_encoded['loan_amnt']\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "y_reg_pred = reg_model.predict(X_reg_test)\n",
    "mse = mean_squared_error(y_reg_test, y_reg_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mean_loan_amount = np.mean(y_reg)\n",
    "\n",
    "print(\"Regression Model Performance:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Loan Amount:\", mean_loan_amount)\n",
    "print(\"RMSE as Percentage of Mean Loan Amount:\", (rmse / mean_loan_amount) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c8da4-8f96-4ce9-91bb-7fb9c578a4fd",
   "metadata": {},
   "source": [
    "29.14% error relative to mean loan amount is quite high. This suggests the model's predictions are not particularly reliable. Try a non-linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f68f82c-1af0-4887-a985-a4d37bdced27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression MSE: 4265221.5875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg_model_rf.fit(X_reg_train, y_reg_train)\n",
    "y_reg_pred_rf = reg_model_rf.predict(X_reg_test)\n",
    "print(\"Random Forest Regression MSE:\", mean_squared_error(y_reg_test, y_reg_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a223211-0530-4bbc-895a-54201200e912",
   "metadata": {},
   "source": [
    "## Things to try to improve it:\n",
    "\n",
    "Random Forest has a higher MSE thean the the Regression Model!\n",
    "\n",
    "### Feature Engineering Enhancements:\n",
    "Objective: Improve model performance by adding or transforming features.\n",
    "\n",
    "#### Explore New Features\n",
    "Check which additional features might be useful in predicting loan default.\n",
    "\n",
    "- Explore features such as:\n",
    "    - debt_to_income (DTI) ratio\n",
    "    - verification_status\n",
    "    - loan_purpose\n",
    "- Add new features based on interactions or transformations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
